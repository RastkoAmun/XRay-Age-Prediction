{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers.utils import CustomImageDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number_of_smaller_set = 636\n",
    "# number_of_smaller_validation_set = 24\n",
    "labels_df = pd.read_csv('data/boneage-training-dataset.csv')\n",
    "training_labels, testing_labels = train_test_split(labels_df, train_size=0.95, test_size=0.05)\n",
    "\n",
    "# training_labels = labels.head(number_of_smaller_set)\n",
    "# validation_labels = labels.tail(number_of_smaller_validation_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boneage</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8926</th>\n",
       "      <td>11495</td>\n",
       "      <td>156</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9710</th>\n",
       "      <td>12373</td>\n",
       "      <td>108</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>1678</td>\n",
       "      <td>132</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12281</th>\n",
       "      <td>15242</td>\n",
       "      <td>150</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9521</th>\n",
       "      <td>12168</td>\n",
       "      <td>150</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8971</th>\n",
       "      <td>11551</td>\n",
       "      <td>120</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>4100</td>\n",
       "      <td>162</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11523</th>\n",
       "      <td>14404</td>\n",
       "      <td>204</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8188</th>\n",
       "      <td>10665</td>\n",
       "      <td>204</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>3927</td>\n",
       "      <td>94</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>631 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  boneage   male\n",
       "8926   11495      156   True\n",
       "9710   12373      108   True\n",
       "269     1678      132  False\n",
       "12281  15242      150   True\n",
       "9521   12168      150   True\n",
       "...      ...      ...    ...\n",
       "8971   11551      120  False\n",
       "2447    4100      162  False\n",
       "11523  14404      204   True\n",
       "8188   10665      204   True\n",
       "2292    3927       94  False\n",
       "\n",
       "[631 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11980\n",
      "631\n"
     ]
    }
   ],
   "source": [
    "transformer = transforms.Compose([\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Using custom dataset to load images \n",
    "training_dataset = CustomImageDataset(\n",
    "  root_dir='data/processed/training-set', labels=training_labels, transform=transformer\n",
    ")\n",
    "testing_dataset = CustomImageDataset(\n",
    "  root_dir='data/processed/training-set', labels=testing_labels, transform=transformer\n",
    ")\n",
    "\n",
    "print(len(training_dataset))\n",
    "print(len(testing_dataset))\n",
    "batch_size = 32\n",
    "# prepared dataloader for neural network (note it is using batch size of 3, just for this sample)\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True)\n",
    "testing_dataloader = DataLoader(testing_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoneAgeModel(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(BoneAgeModel, self).__init__()\n",
    "\n",
    "    self.cnn = nn.Sequential(\n",
    "      nn.Conv2d(1, 32, kernel_size=2, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "      nn.Conv2d(32, 64, kernel_size=2, padding=1),\n",
    "      nn.ReLU(),\n",
    "      nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "      nn.Flatten(),\n",
    "\n",
    "      nn.Linear(64 * (256 // 4) * (344 // 4), 128),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(128, 1)\n",
    "    )\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.cnn(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 31.45\n",
      "Epoch 2/10, Loss: 27.07\n",
      "Epoch 3/10, Loss: 25.00\n",
      "Epoch 4/10, Loss: 23.41\n",
      "Epoch 5/10, Loss: 22.05\n",
      "Epoch 6/10, Loss: 20.97\n",
      "Epoch 7/10, Loss: 19.21\n",
      "Epoch 8/10, Loss: 17.81\n",
      "Epoch 9/10, Loss: 16.32\n",
      "Epoch 10/10, Loss: 15.20\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = BoneAgeModel()\n",
    "criterion = nn.L1Loss() # Mean Squared Error for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for images, ages, _, _ in training_dataloader:  # Batch size = 12\n",
    "        ages = ages.float()\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(images).squeeze()\n",
    "        loss = criterion(predictions, ages)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss / len(training_dataloader):.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11495    156.0   164.60\n",
      " 12373    108.0   145.53\n",
      "  1678    132.0   129.55\n",
      " 15242    150.0   145.10\n",
      " 12168    150.0   135.48\n",
      "  7225    168.0   130.31\n",
      "  5744    168.0   160.27\n",
      "  2509    162.0   160.39\n",
      " 11814    150.0   138.19\n",
      "  3043    156.0   151.47\n",
      " 11005    156.0   143.16\n",
      "  9928     42.0    58.59\n",
      "  1567     69.0    83.46\n",
      " 12028    106.0    95.73\n",
      "  4563    132.0   173.60\n",
      " 11795     96.0    69.36\n",
      " 15095    150.0   141.82\n",
      " 13930    138.0   114.61\n",
      "  7551    132.0   142.41\n",
      " 12357    150.0   125.21\n",
      " 14955    120.0   144.11\n",
      "  7270     82.0   100.05\n",
      "  6430    162.0   124.64\n",
      "  4215     94.0   145.24\n",
      "  3892    162.0   155.28\n",
      " 14141    132.0   125.67\n",
      " 15260    132.0   131.01\n",
      "  8884    106.0    80.17\n",
      "  1460     96.0    79.31\n",
      " 12994    132.0   155.35\n",
      " 12821     72.0    76.19\n",
      "  3065     82.0   122.00\n",
      "  2697     42.0   115.92\n",
      " 11498     42.0    12.32\n",
      " 11596    132.0   130.01\n",
      " 10454    138.0   125.64\n",
      " 13889    138.0   160.32\n",
      "  5342    120.0   116.19\n",
      "  7687    106.0   120.28\n",
      " 15064    204.0   161.25\n",
      " 15183    120.0   133.76\n",
      "  8261    120.0   118.79\n",
      "  2071    180.0   130.84\n",
      "  4102     69.0    57.87\n",
      " 14007     82.0    92.77\n",
      "  2121    150.0   141.73\n",
      "  5362    156.0   100.33\n",
      " 10866    162.0   150.74\n",
      " 14762    144.0   165.72\n",
      "  6611    156.0    77.83\n",
      "  8069    138.0   128.00\n",
      "  2255    144.0   150.60\n",
      "  4983     84.0   110.76\n",
      "  4194     58.0   108.21\n",
      " 13280    168.0   164.15\n",
      " 11527    132.0   154.96\n",
      " 12118     60.0    71.08\n",
      " 14696    144.0   152.38\n",
      "  9810    126.0   114.40\n",
      "  2105    150.0   153.85\n",
      "  3299    156.0   177.55\n",
      " 10051    150.0   116.95\n",
      "  7343    156.0   149.81\n",
      "  6129    150.0   120.17\n",
      "  2510    192.0    92.55\n",
      " 13783    168.0   167.16\n",
      " 10063    204.0   183.55\n",
      "  2187    144.0   155.75\n",
      "  2416    150.0   123.09\n",
      "  6315     96.0    90.66\n",
      "  6949    150.0   161.41\n",
      " 14710    159.0   132.48\n",
      "  2562    168.0   116.78\n",
      "  8415    106.0   114.88\n",
      " 11784    135.0   129.43\n",
      " 10652    162.0   178.89\n",
      " 12633     69.0    79.73\n",
      " 11417    159.0   154.88\n",
      "  3284    132.0   155.85\n",
      "  8001    168.0   137.12\n",
      "  4891     60.0   125.18\n",
      "  9017    138.0   123.62\n",
      " 12013    156.0   104.52\n",
      "  9094    106.0   146.13\n",
      "  6636     72.0    90.61\n",
      " 15051     36.0    81.61\n",
      " 10965     82.0    75.23\n",
      "  9878    102.0   131.37\n",
      " 15452    132.0   103.71\n",
      " 11451    120.0   147.26\n",
      "  8517    106.0   112.89\n",
      " 12130    138.0   128.13\n",
      "  9302    108.0    84.96\n",
      "  4676    100.0   121.40\n",
      "  4707     96.0   125.92\n",
      " 13306     84.0    87.99\n",
      "  2819    120.0   105.60\n",
      " 11029     54.0    75.76\n",
      " 11236    156.0   136.99\n",
      "  6143    162.0   153.17\n",
      "  2013    156.0   146.35\n",
      " 15213     60.0    66.51\n",
      "  5302    120.0   119.15\n",
      "  5420    216.0   124.57\n",
      "  2175     28.0    76.75\n",
      " 13515     94.0    91.52\n",
      " 15499    156.0   130.44\n",
      "  1835     42.0    97.41\n",
      " 11668    228.0   154.68\n",
      " 13371     72.0    80.19\n",
      "  8981    159.0   165.45\n",
      " 12799     77.0    83.84\n",
      "  6995    138.0   147.19\n",
      " 12266    106.0    97.92\n",
      "  4667     84.0   133.84\n",
      " 10331     94.0   125.49\n",
      " 12902    150.0   110.28\n",
      "  7712     60.0    63.35\n",
      "  2143    120.0   139.75\n",
      "  7676    156.0   141.33\n",
      "  9230    168.0   152.46\n",
      "  9233     96.0   127.85\n",
      "  6331    113.0   112.03\n",
      "  6993    180.0   140.89\n",
      "  8984     82.0   110.38\n",
      "  1846    168.0   160.61\n",
      "  7203    106.0   124.04\n",
      "  6020    132.0   114.17\n",
      " 14358     84.0    77.51\n",
      " 11992    132.0   119.20\n",
      "  6484    106.0   134.40\n",
      "  6155     96.0   104.03\n",
      "  4664    156.0   113.51\n",
      " 15036    132.0   146.09\n",
      " 15047     42.0    80.13\n",
      "  3925    180.0   113.31\n",
      " 11158     82.0   103.18\n",
      "  1815     69.0   123.20\n",
      " 14435    138.0   134.90\n",
      "  8685     54.0    55.22\n",
      " 12921    120.0   109.01\n",
      " 10220    150.0   120.74\n",
      " 13005    138.0   118.77\n",
      "  6378     54.0   109.26\n",
      " 15543    144.0   168.09\n",
      " 11286    180.0   146.32\n",
      " 14063    132.0   128.38\n",
      " 13562     96.0    86.09\n",
      "  7782    192.0   129.41\n",
      " 10542     45.0    64.41\n",
      "  1682    106.0   114.77\n",
      "  3654     66.0    79.26\n",
      " 12866    120.0    87.26\n",
      " 11809    132.0   128.61\n",
      " 11018    132.0   113.09\n",
      " 12271    153.0   164.69\n",
      " 12534    156.0   140.41\n",
      "  8600    180.0   136.08\n",
      " 12085    162.0   167.34\n",
      "  1656    144.0   142.20\n",
      "  7592    168.0   165.40\n",
      "  6843    132.0   101.62\n",
      "  5414    156.0   171.30\n",
      " 15339     94.0    74.23\n",
      "  8379     96.0   117.84\n",
      "  2879    168.0   114.37\n",
      "  6663     48.0    52.41\n",
      "  7135    168.0   143.17\n",
      "  9645    132.0   136.18\n",
      "  3271    160.0   164.30\n",
      "  2428    192.0   133.71\n",
      " 15584     54.0   100.15\n",
      " 15038    120.0   149.66\n",
      " 13893    216.0   172.73\n",
      "  8093    144.0   144.81\n",
      " 15447    132.0   128.89\n",
      "  7468     96.0   108.30\n",
      "  5643     72.0    89.49\n",
      "  4779    156.0   147.37\n",
      "  5666    192.0   151.65\n",
      " 13334     88.0   103.30\n",
      " 11850    162.0   158.31\n",
      "  3042    106.0    62.57\n",
      "  2642     84.0   132.39\n",
      "  2653    168.0   161.04\n",
      " 14688    106.0   127.56\n",
      "  6015    198.0   119.19\n",
      " 10867    150.0   119.55\n",
      "  9709    144.0   115.05\n",
      " 11046    168.0   155.67\n",
      "  4358    204.0   154.53\n",
      " 14798    216.0   157.24\n",
      " 14586    108.0   105.18\n",
      "  7326     94.0   106.38\n",
      " 12588    204.0   144.15\n",
      "  7038     46.0    49.67\n",
      "  3846    156.0   146.58\n",
      " 14909    132.0   141.20\n",
      " 14324     82.0    76.41\n",
      "  1711     55.0    97.21\n",
      " 14403     72.0    82.96\n",
      "  6002    150.0   134.47\n",
      " 12881    204.0   188.30\n",
      "  3707    144.0   174.27\n",
      " 12042    106.0   128.50\n",
      " 15133    180.0   154.26\n",
      "  3283    168.0   160.87\n",
      "  1423     94.0   130.35\n",
      " 15022     69.0    98.29\n",
      "  1969    138.0   110.09\n",
      "  2344    204.0   142.82\n",
      "  4739    120.0    93.13\n",
      "  5059    132.0   107.03\n",
      "  6541     82.0   110.08\n",
      "  8871    120.0   112.52\n",
      "  9920     24.0    22.97\n",
      "  6292     50.0    87.36\n",
      "  6201     82.0    99.76\n",
      " 10399     60.0    62.09\n",
      "  8916     72.0    67.59\n",
      "  5786    162.0   154.39\n",
      " 10512     72.0    65.21\n",
      " 11964    120.0   120.06\n",
      " 15128    132.0   102.63\n",
      " 13010    138.0   127.51\n",
      "  3601    156.0   123.51\n",
      "  8462    156.0   159.70\n",
      " 10746    102.0   115.25\n",
      "  8820    162.0   161.77\n",
      " 11743    120.0   135.89\n",
      " 13148     82.0   104.11\n",
      "  9074     72.0    74.79\n",
      "  2568    168.0   108.36\n",
      " 15540     84.0   101.21\n",
      "  5958    120.0   157.84\n",
      "  8121    144.0    88.44\n",
      "  3979     84.0   109.57\n",
      " 11701    106.0   153.81\n",
      " 11832    108.0   132.17\n",
      " 10636    150.0   163.45\n",
      " 10481    132.0   136.12\n",
      "  2427    180.0   121.96\n",
      " 13780     32.0   201.56\n",
      " 10806    156.0   139.63\n",
      " 10842    144.0   121.51\n",
      "  1634     82.0    99.58\n",
      " 14588    162.0   159.63\n",
      " 13044    156.0   118.02\n",
      "  5866     78.0    75.96\n",
      " 14990    120.0   136.37\n",
      "  4811    156.0   141.56\n",
      "  1377    180.0   133.95\n",
      " 11293    132.0   156.71\n",
      " 13026     94.0    95.26\n",
      " 14025     72.0   124.03\n",
      "  7057    162.0   149.58\n",
      "  5756    108.0    74.61\n",
      "  7108    132.0   150.53\n",
      "  1571    102.0    97.67\n",
      " 13228     94.0   119.73\n",
      "  2367    180.0   136.14\n",
      " 13753    132.0   119.43\n",
      " 12738    210.0   185.97\n",
      " 12604    186.0   151.79\n",
      "  7029     84.0   115.71\n",
      " 10450     50.0    86.86\n",
      " 12252    132.0   133.86\n",
      "  2664    156.0   156.68\n",
      "  7721    138.0   149.05\n",
      "  9737    150.0   109.58\n",
      "  2806    180.0   133.09\n",
      " 10556    138.0   124.72\n",
      " 10137    150.0   134.69\n",
      "  2159     21.0   126.10\n",
      "  3670    192.0   166.66\n",
      " 11799    150.0   122.57\n",
      " 12285    165.0   127.01\n",
      "  5184     84.0    95.77\n",
      " 13634    156.0   126.84\n",
      " 10316    156.0   121.79\n",
      " 14865     94.0    68.81\n",
      "  3672     78.0   107.02\n",
      " 11894    150.0   135.81\n",
      " 14103    144.0   126.74\n",
      "  7952     30.0    98.08\n",
      "  2875    144.0   104.77\n",
      "  8970    132.0   139.20\n",
      " 12298    106.0   121.80\n",
      "  5045     72.0    84.05\n",
      "  7300    106.0   111.63\n",
      "  7073    144.0   170.17\n",
      " 14565     60.0    95.09\n",
      "  7290    168.0   127.91\n",
      " 12608    162.0   125.11\n",
      " 13050    106.0   155.62\n",
      " 15139     39.0    87.54\n",
      " 13197    162.0   137.91\n",
      " 10939    132.0   130.95\n",
      " 12126    126.0   126.14\n",
      " 10699    120.0   133.59\n",
      "  3235    144.0   149.70\n",
      "  1865    139.0   122.40\n",
      " 10701    144.0   143.23\n",
      " 15229    156.0   117.88\n",
      " 15251     69.0   102.13\n",
      " 11588    120.0   125.46\n",
      " 14790    106.0   117.99\n",
      "  9736    108.0   101.47\n",
      " 11866    168.0   170.04\n",
      "  6626    156.0   170.68\n",
      "  8613    150.0   116.29\n",
      "  2136    115.0   128.86\n",
      "  2591    186.0   157.61\n",
      " 14745    144.0   126.50\n",
      "  1863      9.0   103.02\n",
      "  8933    120.0   117.12\n",
      "  6828    132.0   130.68\n",
      "  7489    120.0   130.55\n",
      "  3677     48.0   140.56\n",
      "  9765    138.0   127.49\n",
      "  8616     82.0    84.57\n",
      "  8544     94.0   106.93\n",
      "  7840     18.0    67.14\n",
      "  1389    138.0   129.26\n",
      " 11558     60.0    76.36\n",
      "  6516    138.0   129.29\n",
      " 12870    101.0   120.67\n",
      " 13114    228.0   185.76\n",
      "  7836    156.0   151.29\n",
      "  7993    162.0   136.34\n",
      " 11283    135.0   111.71\n",
      "  9667     69.0   111.11\n",
      " 10183    162.0   157.66\n",
      "  4008    106.0   140.47\n",
      " 12685    132.0   145.93\n",
      " 13792    162.0   164.48\n",
      "  7909    120.0   120.26\n",
      " 12054    168.0   159.03\n",
      "  3839    144.0   120.07\n",
      "  1796    162.0   122.79\n",
      "  5772    114.0   108.61\n",
      "  7503    168.0   174.03\n",
      "  1707    106.0   158.08\n",
      " 15528    156.0   149.11\n",
      "  9415    150.0   117.48\n",
      "  6734    165.0   147.74\n",
      " 11476    162.0   178.40\n",
      "  9374    156.0   165.93\n",
      " 13108    120.0   110.22\n",
      " 14461    144.0   156.06\n",
      "  6858    162.0   173.39\n",
      " 14193     96.0   114.11\n",
      " 12407    159.0   142.52\n",
      "  5437    132.0   128.56\n",
      " 15069     21.0    68.11\n",
      " 11630     46.0    74.74\n",
      " 11616    162.0   133.74\n",
      "  8718    150.0   144.26\n",
      "  9339    120.0   116.54\n",
      " 14533    106.0    96.86\n",
      " 11602    162.0   147.40\n",
      " 10100    138.0   154.63\n",
      "  3133     82.0   140.82\n",
      " 12710    132.0   116.78\n",
      " 12888     82.0    73.55\n",
      " 13599    180.0   137.92\n",
      " 12765    174.0   154.12\n",
      "  1674    150.0   127.52\n",
      " 12125     82.0    92.88\n",
      " 10844     48.0   187.12\n",
      "  8138     82.0    62.89\n",
      "  6239    132.0   155.49\n",
      "  7303    138.0   115.25\n",
      " 12203    168.0   173.57\n",
      "  9594     72.0    64.13\n",
      " 10658    132.0   127.30\n",
      "  4660    156.0   130.87\n",
      "  2788     84.0   114.38\n",
      " 12246    120.0   133.62\n",
      "  1652    156.0   139.90\n",
      "  7560    132.0   115.87\n",
      "  7857    168.0   140.14\n",
      " 13618     60.0    96.74\n",
      "  9392    204.0   166.99\n",
      "  7431    102.0   101.11\n",
      "  6929    204.0   152.59\n",
      "  3897     32.0    84.06\n",
      "  5518    132.0   141.06\n",
      "  3812     42.0   102.56\n",
      "  2030     24.0   153.70\n",
      " 10319    144.0   138.42\n",
      "  5504    144.0   141.11\n",
      " 13616    174.0   108.49\n",
      "  4836     28.0    40.61\n",
      "  5724    192.0   148.84\n",
      " 11279    106.0   121.68\n",
      " 11697    120.0   133.47\n",
      "  8879     96.0   130.59\n",
      "  2070     58.0   120.23\n",
      " 13756    162.0   141.93\n",
      "  4271    132.0   154.00\n",
      "  5858    168.0   151.96\n",
      " 13156    132.0   108.80\n",
      " 15565    132.0   142.57\n",
      " 12853    106.0    93.88\n",
      " 13988    156.0   126.81\n",
      "  8959    156.0   160.45\n",
      " 11900    132.0   144.73\n",
      " 12004     42.0     9.66\n",
      " 14036    180.0   160.84\n",
      " 11419    144.0   107.38\n",
      "  8526     94.0   121.77\n",
      "  6158    162.0   158.70\n",
      "  9819     60.0   120.04\n",
      "  5759    168.0   146.51\n",
      "  8122    120.0   121.20\n",
      " 14549    106.0   135.65\n",
      "  9850    180.0   119.00\n",
      " 11103    144.0   125.07\n",
      " 10258     82.0    87.76\n",
      " 15097    120.0   109.03\n",
      " 11771    144.0   142.55\n",
      "  2235    168.0   162.71\n",
      "  2352     15.0   114.89\n",
      "  7688     82.0   108.76\n",
      "  7084    168.0   119.68\n",
      " 12060     82.0   113.23\n",
      "  8610    138.0    68.92\n",
      "  9506    106.0   121.34\n",
      " 10150    144.0   140.55\n",
      " 11014    168.0   121.90\n",
      " 14828     94.0   119.26\n",
      " 11594    165.0   148.75\n",
      "  4978     72.0    83.56\n",
      "  9882    168.0   157.44\n",
      " 11860    150.0   151.64\n",
      "  9541    138.0   115.47\n",
      " 15313    159.0   153.30\n",
      "  7272     82.0   135.47\n",
      "  9441     72.0    81.11\n",
      " 11487    162.0   175.24\n",
      " 14085    156.0   137.81\n",
      "  5291    132.0   161.73\n",
      " 11237     57.0    90.13\n",
      " 13976    162.0   185.64\n",
      " 13440    144.0   154.71\n",
      " 10429    168.0   176.50\n",
      " 13093    132.0   121.84\n",
      "  5436    144.0   114.71\n",
      "  9886     94.0    79.09\n",
      " 11726    150.0   203.18\n",
      "  5321    204.0   142.32\n",
      " 12303     60.0    80.85\n",
      "  1825    132.0   137.00\n",
      " 12343     94.0   130.95\n",
      "  3074    120.0   151.87\n",
      "  5131    108.0   109.81\n",
      " 14364     94.0   131.11\n",
      "  5951    156.0   147.23\n",
      "  7048    120.0   110.26\n",
      "  8882    162.0   174.40\n",
      "  7906     82.0    74.25\n",
      "  3883    120.0   116.19\n",
      "  7986    144.0   154.53\n",
      " 14213     94.0   123.62\n",
      "  3413    138.0   134.26\n",
      "  7372     94.0   109.23\n",
      " 12000    168.0   120.23\n",
      "  4741     96.0   101.70\n",
      " 10536    186.0   165.80\n",
      " 11641    106.0   117.93\n",
      "  7283    192.0   179.23\n",
      " 12991     60.0   116.44\n",
      "  5448    168.0   118.99\n",
      "  6059    100.0   145.46\n",
      " 12525    138.0   119.17\n",
      "  4633    132.0   136.78\n",
      " 14876    106.0   115.37\n",
      " 13773    150.0    96.21\n",
      " 10219    106.0    99.55\n",
      " 10039     96.0   124.63\n",
      " 14559     94.0   125.96\n",
      " 12871    144.0   144.99\n",
      " 11466    156.0   158.29\n",
      "  8888    144.0   122.49\n",
      " 10178    162.0   132.22\n",
      " 11329    162.0   147.18\n",
      "  9551    150.0   152.06\n",
      "  9209    100.0    78.37\n",
      "  9228    180.0   110.47\n",
      " 11603     66.0    77.30\n",
      "  2779    168.0   141.77\n",
      "  1727    156.0   149.98\n",
      "  4111    120.0   129.78\n",
      " 14115     69.0    70.74\n",
      "  4350    144.0   137.81\n",
      "  5961     48.0    54.46\n",
      "  9826    114.0   129.58\n",
      "  2829    165.0   148.65\n",
      " 11707    120.0   101.16\n",
      " 10992    138.0    91.96\n",
      " 14515    132.0   124.83\n",
      "  5735    156.0   149.03\n",
      "  5162    180.0   190.98\n",
      " 14621    120.0   123.99\n",
      "  2285    168.0   127.82\n",
      " 15591    162.0   161.81\n",
      " 14429     84.0    90.65\n",
      " 10433     94.0   141.67\n",
      " 13133    162.0   147.49\n",
      "  9314    156.0   147.11\n",
      "  6568    120.0   145.58\n",
      "  8256    168.0   167.04\n",
      "  6630     82.0   102.15\n",
      "  3632    144.0   133.02\n",
      " 12681    132.0   124.57\n",
      " 12570    162.0   152.89\n",
      " 12370    132.0   121.39\n",
      " 15296     82.0    81.59\n",
      " 14895    132.0   144.03\n",
      "  2614    138.0   140.81\n",
      "  2442    168.0   168.68\n",
      " 10147    156.0   137.92\n",
      "  3136    174.0   149.40\n",
      "  6332    162.0   148.22\n",
      "  4048    144.0   166.91\n",
      " 10275    156.0   147.62\n",
      " 14067    156.0   144.28\n",
      " 13981    132.0   151.75\n",
      " 15359    156.0   188.26\n",
      "  7862    132.0   139.42\n",
      "  2917    132.0   124.23\n",
      " 15441    132.0   127.36\n",
      " 11628    204.0   167.45\n",
      "  5982    138.0   124.32\n",
      "  7098    144.0   125.79\n",
      "  6607    156.0   117.79\n",
      "  5096     96.0   121.07\n",
      "  4814    156.0   157.47\n",
      "  7140     94.0    87.00\n",
      "  4188    186.0   163.23\n",
      "  8650    132.0   155.74\n",
      " 10053     84.0   122.23\n",
      "  8771    132.0   117.22\n",
      "  6366    126.0   137.18\n",
      "  1554     94.0   153.08\n",
      "  4623     60.0    78.23\n",
      "  7402    156.0   149.65\n",
      "  6058     48.0    57.39\n",
      " 12649    204.0   172.03\n",
      "  4618     88.0   118.98\n",
      "  7700    162.0   151.14\n",
      " 15057     90.0   117.25\n",
      "  4765    144.0   125.75\n",
      " 11276    168.0   126.21\n",
      " 14474    165.0   146.69\n",
      " 12229    120.0   112.64\n",
      " 14839    156.0   115.63\n",
      "  2424     69.0   126.11\n",
      " 10880    120.0   151.32\n",
      " 14532     82.0   116.22\n",
      "  2360    162.0   102.51\n",
      "  7047     94.0   110.23\n",
      " 12217     69.0    74.95\n",
      " 11402     69.0    61.43\n",
      " 12294    108.0   100.79\n",
      "  7259     84.0    44.72\n",
      " 14101    156.0   133.12\n",
      " 11501    106.0    92.09\n",
      " 13739     94.0   112.60\n",
      " 14405    144.0   127.11\n",
      " 11561    156.0   172.59\n",
      "  3945    144.0   107.89\n",
      " 13451    156.0   131.11\n",
      "  8892    132.0   127.79\n",
      "  3281    106.0   107.51\n",
      " 11812     60.0    95.56\n",
      " 15107     36.0    59.81\n",
      "  4647    132.0   128.08\n",
      " 12562    144.0    94.53\n",
      "  5244    144.0   128.23\n",
      " 15304     69.0    65.11\n",
      "  3584    120.0   112.85\n",
      " 11201     69.0    85.77\n",
      "  6885    156.0   105.05\n",
      " 11250    168.0   145.04\n",
      "  9133     84.0    70.19\n",
      " 11215     94.0   107.81\n",
      "  9586     96.0    86.31\n",
      " 14011    138.0   118.19\n",
      " 12247    138.0   131.82\n",
      " 13427    168.0   147.61\n",
      " 15088    120.0   135.21\n",
      " 12470     72.0    71.46\n",
      "  5907    198.0   137.55\n",
      " 15190    204.0   164.84\n",
      "  6049     96.0    88.46\n",
      "  8188    162.0   142.34\n",
      " 10458    138.0   118.26\n",
      " 14631    168.0   137.27\n",
      "  5656    168.0   162.91\n",
      " 14568    132.0   141.37\n",
      "  6780     69.0    82.20\n",
      "  9191    168.0   138.48\n",
      "  9451    162.0   177.85\n",
      " 11587    106.0   120.97\n",
      "  4310     60.0   135.10\n",
      "  6330    156.0   140.49\n",
      "  5542     60.0   164.41\n",
      " 14707    156.0   117.60\n",
      " 12161     18.0    53.12\n",
      " 10373    100.0   162.75\n",
      "  7647     42.0    93.02\n",
      "  5588    156.0   137.32\n",
      " 14960     94.0    69.16\n",
      " 13246    132.0   114.69\n",
      " 11970    180.0   176.83\n",
      " 13057    156.0    73.82\n",
      "  6465    156.0   170.60\n",
      "  4859    156.0   142.10\n",
      " 12443     72.0    81.55\n",
      "  9557    132.0   107.02\n",
      "  9790    108.0   158.40\n",
      "  3621     96.0   147.98\n",
      "  9237    112.0   117.73\n",
      " 11307    156.0   192.06\n",
      " 11551    120.0   114.50\n",
      "  4100    162.0   139.81\n",
      " 14404    204.0   163.47\n",
      " 10665    204.0   185.12\n",
      "  3927     94.0   138.47\n",
      "\n",
      "✅ Validation Loss: 725.4657\n",
      "📁 Submission file saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Ensure model is in evaluation mode\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "epoch_val_loss = 0  # Track validation loss\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, ages, gender, img_ids in testing_dataloader:  # `img_ids` is a batch\n",
    "        predictions = model(images).squeeze()  # Get batched predictions\n",
    "\n",
    "        # Loop through each item in the batch\n",
    "        for i in range(len(img_ids)):  \n",
    "            test_predictions.append([img_ids[i].item(), predictions[i].item()])  # ✅ Convert each tensor to scalar\n",
    "\n",
    "            loss = criterion(predictions[i], ages[i].float())  # ✅ Ensure float type\n",
    "            epoch_val_loss += loss.item()\n",
    "\n",
    "            print(f\"{img_ids[i].item():>6} {ages[i].item():>8} {predictions[i].item():>8.2f}\")\n",
    "\n",
    "# Compute final validation loss\n",
    "val_loss = epoch_val_loss / len(testing_dataloader)\n",
    "print(f\"\\n✅ Validation Loss: {val_loss:.4f}\")  # Final validation loss\n",
    "\n",
    "# Save predictions to CSV\n",
    "submission_df = pd.DataFrame(test_predictions, columns=[\"id\", \"bone_age\"])\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"📁 Submission file saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boneage</th>\n",
       "      <th>male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12587</th>\n",
       "      <td>15583</td>\n",
       "      <td>132</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12588</th>\n",
       "      <td>15584</td>\n",
       "      <td>54</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12589</th>\n",
       "      <td>15585</td>\n",
       "      <td>162</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12590</th>\n",
       "      <td>15586</td>\n",
       "      <td>192</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12591</th>\n",
       "      <td>15587</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12592</th>\n",
       "      <td>15588</td>\n",
       "      <td>113</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12593</th>\n",
       "      <td>15589</td>\n",
       "      <td>84</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12594</th>\n",
       "      <td>15591</td>\n",
       "      <td>162</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12595</th>\n",
       "      <td>15593</td>\n",
       "      <td>180</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12596</th>\n",
       "      <td>15594</td>\n",
       "      <td>108</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12597</th>\n",
       "      <td>15595</td>\n",
       "      <td>78</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12598</th>\n",
       "      <td>15596</td>\n",
       "      <td>72</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12599</th>\n",
       "      <td>15597</td>\n",
       "      <td>192</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12600</th>\n",
       "      <td>15598</td>\n",
       "      <td>120</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12601</th>\n",
       "      <td>15599</td>\n",
       "      <td>36</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12602</th>\n",
       "      <td>15600</td>\n",
       "      <td>144</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12603</th>\n",
       "      <td>15602</td>\n",
       "      <td>82</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12604</th>\n",
       "      <td>15603</td>\n",
       "      <td>106</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12605</th>\n",
       "      <td>15604</td>\n",
       "      <td>168</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12606</th>\n",
       "      <td>15605</td>\n",
       "      <td>50</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12607</th>\n",
       "      <td>15606</td>\n",
       "      <td>113</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12608</th>\n",
       "      <td>15608</td>\n",
       "      <td>55</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12609</th>\n",
       "      <td>15609</td>\n",
       "      <td>150</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12610</th>\n",
       "      <td>15610</td>\n",
       "      <td>132</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  boneage   male\n",
       "12587  15583      132   True\n",
       "12588  15584       54   True\n",
       "12589  15585      162   True\n",
       "12590  15586      192   True\n",
       "12591  15587       50  False\n",
       "12592  15588      113  False\n",
       "12593  15589       84   True\n",
       "12594  15591      162   True\n",
       "12595  15593      180   True\n",
       "12596  15594      108   True\n",
       "12597  15595       78   True\n",
       "12598  15596       72   True\n",
       "12599  15597      192   True\n",
       "12600  15598      120  False\n",
       "12601  15599       36   True\n",
       "12602  15600      144  False\n",
       "12603  15602       82  False\n",
       "12604  15603      106  False\n",
       "12605  15604      168   True\n",
       "12606  15605       50  False\n",
       "12607  15606      113  False\n",
       "12608  15608       55  False\n",
       "12609  15609      150   True\n",
       "12610  15610      132   True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
